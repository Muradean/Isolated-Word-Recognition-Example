{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A HMM-GMM model (3 senones per HMM AND GMMs are modeled by a single Gaussian Distribution)\n",
    "\n",
    "# Inspired by lab 2 from DT2119 course from KTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from math import e\n",
    "import numpy\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import inv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pedro/Desktop/Gaussian_Mixture_Models-EM/Sistema_Basico\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "test_path = os.getcwd() + \"/train/animals\"\n",
    "folders = os.listdir(test_path)\n",
    "\n",
    "recordings = {}\n",
    "\n",
    "#Generates a dictionary with the mfccs for each recording\n",
    "for folder in folders:\n",
    "    filenames = os.listdir(test_path + \"/\" + folder)\n",
    "    recordings[folder] = []\n",
    "    for fn in filenames:\n",
    "        filepath = test_path + \"/\" + folder + \"/\" + fn\n",
    "        y, sr = librosa.load(filepath)\n",
    "        wav, _ = librosa.effects.trim(y)\n",
    "        mfcc = librosa.feature.mfcc(y=wav,sr=sr, n_mfcc=13)\n",
    "        recordings[folder].append(mfcc.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HMM class\n",
    "\n",
    "<p> O processo de classificação de um recording funciona da seguinte maneira: Os HMMs correspondentes a cada palavra do sistema vão ser iterados com a sequência de MFCCs que vai servir de input à função log_multivariate_normal_density. O output desta função vai ser uma matriz com NxM em que N é o número de frames e M o número de estados da HMM. De notar que neste exemplo o GMM só tem uma gaussiana. Caso tivesse mais a única coisa que mudava era que o resultado era uma soma ponderada das gaussianas. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:105: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def logsumexp(arr,axis=0):\n",
    "    '''Computes the sum of arr assuming arr is in the log domain.\n",
    "    Returns log(sum(exp(arr))) while minimizing the possibility of over/underflow\n",
    "    '''\n",
    "\n",
    "    arr = np.rollaxis(arr,axis)\n",
    "    vmax = arr.max(axis = 0)\n",
    "    if vmax.ndim > 0:\n",
    "        vmax[~np.isfinite(vmax)] = 0\n",
    "    elif not np.isfinite(vmax):\n",
    "        vmax = 0\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        out = np.log(np.sum(np.exp(arr-vmax),axis=0))\n",
    "        out += vmax\n",
    "        return out\n",
    "\n",
    "\n",
    "'''Created matrices will have 4 states.\n",
    "A first,middle, last one and a transition one'''\n",
    "class WordHMM:\n",
    "    def __init__(self,word, data, n_states = 3, n_mfccs = 13):\n",
    "        \n",
    "        self.word = word\n",
    "        self.data = data\n",
    "        self.n_states = n_states\n",
    "        self.n_mfccs = n_mfccs\n",
    "        \n",
    "\n",
    "        #Transition Probabilities\n",
    "        self.startprob = np.zeros((n_states + 1, 1)) #Existe mais um estado inicial que e o de fim\n",
    "        self.transmat = np.zeros((n_states + 1, n_states + 1))\n",
    "\n",
    "        #Emission probabilities - There are 13 emissions  for each state.\n",
    "        self.means = np.zeros((n_states, n_mfccs))  #Esta bem. A media  do estado extra nao conta\n",
    "        self.covars=  np.zeros((n_states, n_mfccs)) #Esta bem a media do estado extra nao conta\n",
    "        self.init_emissions()\n",
    "        self.init_transitions()\n",
    "        \n",
    "    def get_word(self):\n",
    "        return self.word\n",
    "    \n",
    "    def get_transmat(self):\n",
    "        return self.transmat\n",
    "    \n",
    "    def get_emission_means(self):\n",
    "        return self.means\n",
    "    \n",
    "    def get_emission_covars(self):\n",
    "        return self.emission\n",
    "    \n",
    "        \n",
    "    '''\n",
    "        This function needs:\n",
    "        -A matrix with the likelihood of a given frame per second.\n",
    "        -An array with the initial probabilities.\n",
    "        -A transition matrix.\n",
    "\n",
    "    '''\n",
    "    def forward_algorithm(self,loglh_senone,log_startprob,log_transmat):\n",
    "        \n",
    "        alpha = np.zeros(loglh_senone.shape)\n",
    "        \n",
    "        #forward initialization\n",
    "        alpha[0]= log_startprob.T + loglh_senone[0]\n",
    "        \n",
    "        for n in range(1,len(alpha)):\n",
    "            for i in range(alpha.shape[1]):\n",
    "                alpha[n,i] = logsumexp(alpha[n -1] + log_transmat[:,i]) + loglh_senone[n,i]\n",
    "                \n",
    "        return alpha, logsumexp(alpha[len(alpha) -1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    '''\n",
    "    Initializes transition matrix (n_states+1Xn_states+1) with uniform distribution and...\n",
    "    Initializes start probabilities\n",
    "    '''\n",
    "    def init_transitions(self):\n",
    "        self.startprob[0] = 1\n",
    "    \n",
    "        for l in range(0,len(self.transmat) - 1):\n",
    "            self.transmat[l][l] = 0.5\n",
    "            self.transmat[l][l+1] = 0.5   \n",
    "                        \n",
    "\n",
    "        #Iterativo6\n",
    "        for x in range(0,45):\n",
    "            #inicializa matriz de transicao\n",
    "            new_trans = np.zeros((self.n_states + 1, self.n_states + 1))\n",
    "\n",
    "            #INSERE ARRAYS VAZIOS PARA AS EMISSOes\n",
    "            emission_frames = []\n",
    "            for _ in range(0,self.n_states):\n",
    "                emission_frames.append([])\n",
    "\n",
    "            #REALIZA VITERBI TRAINING PARA TODOS OS RECORDINGS     \n",
    "            for recording in self.data:\n",
    "                loglh_senone = self.log_multivariate_normal_density(recording.T)\n",
    "                viterbi_loglik, viterbi_path = self.viterbi(loglh_senone,np.log(self.startprob[:-1]),np.log(self.transmat[:-1,:-1]))\n",
    "\n",
    "                #Transicao: INCREMENTA MATRIZ DE TRANSICAO\n",
    "                for x in range(0,len(viterbi_path) -1 ):\n",
    "                    new_trans[viterbi_path[x],viterbi_path[x+1]] +=1\n",
    "\n",
    "                #EMISSAO: ADICIONA FRAMES A CADA ESTADO ALIGNEMENT\n",
    "                for x in range(0,len(viterbi_path)):\n",
    "                    emission_frames[viterbi_path[x]].append(recording[x])\n",
    "\n",
    "\n",
    "            #SOMA VALORES POR ROW\n",
    "            sum_across_rows = [sum(e) for e in new_trans]\n",
    "\n",
    "            #CONVERTE MATRIZ DE TRANSICAO PARA PROBABILIDADES\n",
    "            for l in range(0,len(new_trans) -1):\n",
    "                for c in range(0,len(new_trans)):\n",
    "                    new_trans[l,c] = new_trans[l,c] / sum_across_rows[l]\n",
    "\n",
    "\n",
    "            for x in range(0,len(emission_frames)):\n",
    "                self.means[x] = np.mean(emission_frames[x],axis=0)\n",
    "                self.covars[x] = np.diag(np.cov(np.array(emission_frames[x]).T))\n",
    "\n",
    "            self.transmat = new_trans\n",
    "            #print(new_trans)\n",
    "\n",
    "        \n",
    "                \n",
    "    def init_emissions(self):\n",
    "        \n",
    "        #Lista de listas(com numero igual ao estados) a partir da qual vai ser calculada a media e o desvio padrao\n",
    "        frames_by_state = []\n",
    "        \n",
    "        #insert empty arrays\n",
    "        for _ in range(0,self.n_states):\n",
    "            frames_by_state.append([])\n",
    "                    \n",
    "        #Para cada gravacao\n",
    "        for recording in self.data:\n",
    "            separated_frames = np.array_split(np.array(recording),3)\n",
    "            \n",
    "            #Para cada lista de frames \n",
    "            for x in range(0,len(separated_frames)):                \n",
    "                for frame in separated_frames[x]:\n",
    "                    frames_by_state[x].append(frame)\n",
    "                    \n",
    "        #Calcula a media e a matriz diagonal de covariancia de cada emissao de cada estado\n",
    "        for x in range(0,len(frames_by_state)):\n",
    "            self.means[x] = np.mean(frames_by_state[x],axis=0)\n",
    "            self.covars[x] = np.diag(np.cov(np.array(frames_by_state[x]).T))\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    '''\n",
    "    This function needs:\n",
    "        -Sequence of MFCC frames.\n",
    "        -Means matrix with the mean value for each MFCC for each senone.\n",
    "        -Diagonal Covariance matrix with the covariance value for each MFCC in each senone.\n",
    "    '''\n",
    "    def log_multivariate_normal_density(self,frames):\n",
    "        frames = frames.T\n",
    "        covars = self.covars\n",
    "        means = self.means\n",
    "        n_samples,n_dim = frames.shape\n",
    "        \n",
    "        \n",
    "        return -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(covars), 1)\n",
    "                      + np.sum((means ** 2) / covars, 1)\n",
    "                      - 2 * np.dot(frames, (means / covars).T)\n",
    "                      + np.dot(frames ** 2, (1.0 / covars).T))\n",
    "    \n",
    "\n",
    "    def viterbiBacktrack(self,B, lastIdx):\n",
    "        \"\"\"Does backtracking retrieving the viterbi path given the most probable\n",
    "            previous indices in each timestep.\n",
    "\n",
    "        Args:\n",
    "            B: NxM array where N are the timesteps and M are the states and each\n",
    "                element contains the most probable state in the previous timestep.\n",
    "            lastIdx: index of the most probable state in timestep N\n",
    "        Returns:\n",
    "            A vector of N-1 elements with the viterbi path\n",
    "        \"\"\"\n",
    "        viterbi_path = [lastIdx]\n",
    "        for i in reversed(range(1, B.shape[0])):\n",
    "            viterbi_path.append(B[i, viterbi_path[-1]])\n",
    "        viterbi_path.reverse()\n",
    "        return np.array(viterbi_path)\n",
    "\n",
    "    \n",
    "    def viterbi(self,log_emlik, log_startprob, log_transmat):\n",
    "        \"\"\"Viterbi path.\n",
    "\n",
    "        Args:\n",
    "            log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "            log_startprob: log probability to start in state i\n",
    "            log_transmat: transition log probability from state i to j\n",
    "\n",
    "        Output:\n",
    "            viterbi_loglik: log likelihood of the best path\n",
    "            viterbi_path: best path\n",
    "        \"\"\"\n",
    "        B = np.zeros(log_emlik.shape, dtype = int)\n",
    "        V = np.zeros(log_emlik.shape)\n",
    "        V[0] = log_startprob.flatten() + log_emlik[0]\n",
    "\n",
    "        for n in range(1, log_emlik.shape[0]):\n",
    "            for j in range(log_emlik.shape[1]):\n",
    "                V[n][j] = np.max(V[n - 1,:] + log_transmat[:,j]) + log_emlik[n, j]\n",
    "                B[n][j] = np.argmax(V[n - 1,:] + log_transmat[:,j])\n",
    "\n",
    "        # Backtrack to take viteri path\n",
    "        viterbi_path = self.viterbiBacktrack(B, np.argmax(V[ log_emlik.shape[0] - 1]))\n",
    "\n",
    "        #print(viterbi_path)\n",
    "        return np.max(V[ log_emlik.shape[0] - 1]), viterbi_path\n",
    "\n",
    "\n",
    "    \n",
    "    def guess_word(self,mfccs):\n",
    "        #print(\"o shape dos mfccs e: \" + str(mfccs.shape))\n",
    "        #Retorna uma matrix com a loglikelihood de cada frame do mfcc pertencer a um senone.\n",
    "        loglh_senone = self.log_multivariate_normal_density(mfccs)\n",
    "        \n",
    "        forward_prob,obs_seq_log_prob = self.forward_algorithm(loglh_senone,np.log(self.startprob[:-1]),np.log(self.transmat[:-1,:-1]))\n",
    "        \n",
    "        viterbi_loglik, viterbi_path = self.viterbi(loglh_senone,np.log(self.startprob[:-1]),np.log(self.transmat[:-1,:-1]))\n",
    "        \n",
    "        return obs_seq_log_prob\n",
    "    \n",
    "    \n",
    "model = {}\n",
    "for word in folders:\n",
    "    model[word] = WordHMM(word, recordings[word])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Perform ASR on a test recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FICHEIRO:cao1.wav\n",
      "estou a iterar com o modelo: vaca res: -2858.5047184355058\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: cão res: -2626.5068309451017\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: grilo res: -3223.858245963852\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: leao res: -3068.8665028454006\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: sapo res: -3242.9699714552853\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: gato res: -2728.8015344464366\n",
      "------------------------------------\n",
      "FICHEIRO:gato4.wav\n",
      "estou a iterar com o modelo: vaca res: -3351.0627414131227\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: cão res: -3166.7213636095908\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:232: RuntimeWarning: divide by zero encountered in log\n",
      "/home/pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:234: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estou a iterar com o modelo: grilo res: -3570.937005674933\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: leao res: -3590.651926295017\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: sapo res: -3806.1212841408096\n",
      "------------------------------------\n",
      "estou a iterar com o modelo: gato res: -3043.615130306499\n",
      "------------------------------------\n",
      "['vaca', 'cão', 'grilo', 'leao', 'sapo', 'gato']\n"
     ]
    }
   ],
   "source": [
    "#Given a file path, extracts the mfccs of that file.\n",
    "def extract_mfccs(filepath):\n",
    "    y, sr = librosa.load(filepath)\n",
    "    wav, _ = librosa.effects.trim(y)\n",
    "    mfccs = librosa.feature.mfcc(y=wav,sr=sr, n_mfcc=13)\n",
    "    return mfccs\n",
    "\n",
    "test_path = os.getcwd() + \"/test\"\n",
    "\n",
    "for file in os.listdir(test_path):\n",
    "    mfccs = extract_mfccs(test_path + \"/\" + file)\n",
    "    print(\"FICHEIRO:\" + str(file))\n",
    "    for word in folders:\n",
    "        res = model[word].guess_word(mfccs)\n",
    "        print(\"estou a iterar com o modelo: \" + str(word) + \" res: \" + str(res))\n",
    "        print(\"------------------------------------\")\n",
    "\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please speak a word into the microphone\n",
      "Iterated word: vaca Score: -3000.3099007128303\n",
      "Iterated word: cão Score: -2972.729534087238\n",
      "Iterated word: grilo Score: -3012.9355184671826\n",
      "Iterated word: leao Score: -2894.3246225996363\n",
      "Iterated word: sapo Score: -3345.537491551016\n",
      "Iterated word: gato Score: -2929.070126893186\n",
      "You said: leao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:232: RuntimeWarning: divide by zero encountered in log\n",
      "/home/pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:234: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "THRESHOLD = 500\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    \"Trim the blank spots at the start and end\"\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    # Trim to the left\n",
    "    snd_data = _trim(snd_data)\n",
    "\n",
    "    # Trim to the right\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
    "    silence = [0] * int(seconds * RATE)\n",
    "    r = array('h', silence)\n",
    "    r.extend(snd_data)\n",
    "    r.extend(silence)\n",
    "    return r\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.5 seconds of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "    \n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "        \n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 30:\n",
    "            break\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    #print(\"a sample_width e: \" + str(sample_width))\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    r = trim(r)\n",
    "    r = add_silence(r, 0.5)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "print(\"please speak a word into the microphone\")\n",
    "record_to_file('demo.wav')\n",
    "#print(\"done - result written to demo.wav\")\n",
    "mfccs = extract_mfccs(os.getcwd() + \"/demo.wav\")\n",
    "\n",
    "\n",
    "maxval = None\n",
    "maxtag = None\n",
    "\n",
    "\n",
    "#itera cada modelo\n",
    "for word in folders:\n",
    "    res = model[word].guess_word(mfccs)\n",
    "    print(\"Iterated word: \" + str(word) + \" Score: \" + str(res))\n",
    "    if(maxval == None or res > maxval):\n",
    "        maxval = res\n",
    "        maxtag = word\n",
    "        \n",
    "print(\"You said: \" + str(maxtag))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
